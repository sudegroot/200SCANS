{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from rfpimp import * # might not be installed already, otherwise install using pip install\n",
    "import collections\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lh_bankssts_volume</th>\n",
       "      <th>lh_caudalanteriorcingulate_volume</th>\n",
       "      <th>lh_caudalmiddlefrontal_volume</th>\n",
       "      <th>lh_cuneus_volume</th>\n",
       "      <th>lh_entorhinal_volume</th>\n",
       "      <th>lh_fusiform_volume</th>\n",
       "      <th>lh_inferiorparietal_volume</th>\n",
       "      <th>lh_inferiortemporal_volume</th>\n",
       "      <th>lh_isthmuscingulate_volume</th>\n",
       "      <th>lh_lateraloccipital_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_Anterior</th>\n",
       "      <th>age_mri</th>\n",
       "      <th>precuneus_volume</th>\n",
       "      <th>-VentralDC</th>\n",
       "      <th>pericalcarine_volume</th>\n",
       "      <th>-Hippocampus</th>\n",
       "      <th>Putamen</th>\n",
       "      <th>Caudate</th>\n",
       "      <th>S</th>\n",
       "      <th>gender_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.012157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>19</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>23</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.468056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>19</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.370714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>18</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>18</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.400928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>19</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.190540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.010043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>22</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.227739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.314423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lh_bankssts_volume  lh_caudalanteriorcingulate_volume  \\\n",
       "0              0.002964                           0.002256   \n",
       "1              0.002344                           0.001850   \n",
       "2              0.002534                           0.002797   \n",
       "3              0.003097                           0.001501   \n",
       "4              0.001972                           0.002460   \n",
       "..                  ...                                ...   \n",
       "136            0.002753                           0.002395   \n",
       "137            0.002515                           0.001864   \n",
       "138            0.002578                           0.001552   \n",
       "139            0.002340                           0.001347   \n",
       "140            0.002148                           0.002235   \n",
       "\n",
       "     lh_caudalmiddlefrontal_volume  lh_cuneus_volume  lh_entorhinal_volume  \\\n",
       "0                         0.008136          0.003394              0.002366   \n",
       "1                         0.005794          0.003879              0.002107   \n",
       "2                         0.006291          0.002592              0.002028   \n",
       "3                         0.006358          0.003707              0.001096   \n",
       "4                         0.007522          0.003739              0.001428   \n",
       "..                             ...               ...                   ...   \n",
       "136                       0.005985          0.002600              0.001503   \n",
       "137                       0.007071          0.003184              0.002057   \n",
       "138                       0.007039          0.003653              0.002337   \n",
       "139                       0.007087          0.002897              0.002138   \n",
       "140                       0.007215          0.004028              0.001970   \n",
       "\n",
       "     lh_fusiform_volume  lh_inferiorparietal_volume  \\\n",
       "0              0.010357                    0.015142   \n",
       "1              0.009607                    0.012305   \n",
       "2              0.008790                    0.012013   \n",
       "3              0.009258                    0.013345   \n",
       "4              0.009609                    0.010374   \n",
       "..                  ...                         ...   \n",
       "136            0.010023                    0.012704   \n",
       "137            0.009190                    0.013648   \n",
       "138            0.010593                    0.012364   \n",
       "139            0.009919                    0.014293   \n",
       "140            0.010835                    0.012245   \n",
       "\n",
       "     lh_inferiortemporal_volume  lh_isthmuscingulate_volume  \\\n",
       "0                      0.011369                    0.003066   \n",
       "1                      0.009720                    0.002845   \n",
       "2                      0.012749                    0.002957   \n",
       "3                      0.010357                    0.002457   \n",
       "4                      0.008492                    0.002886   \n",
       "..                          ...                         ...   \n",
       "136                    0.012537                    0.002785   \n",
       "137                    0.012823                    0.003270   \n",
       "138                    0.010617                    0.002702   \n",
       "139                    0.011200                    0.002929   \n",
       "140                    0.010998                    0.002869   \n",
       "\n",
       "     lh_lateraloccipital_volume  ...  CC_Anterior  age_mri  precuneus_volume  \\\n",
       "0                      0.012157  ...     0.000750       19          0.010798   \n",
       "1                      0.013617  ...     0.000802       23          0.009305   \n",
       "2                      0.012521  ...     0.000915       19          0.010651   \n",
       "3                      0.015477  ...     0.000893       18          0.010617   \n",
       "4                      0.013569  ...     0.000869       18          0.010552   \n",
       "..                          ...  ...          ...      ...               ...   \n",
       "136                    0.013129  ...     0.001073       19          0.009620   \n",
       "137                    0.010043  ...     0.000735       22          0.011233   \n",
       "138                    0.014111  ...     0.000791       22          0.010226   \n",
       "139                    0.012897  ...     0.000938       20          0.010535   \n",
       "140                    0.014132  ...     0.000740       22          0.010066   \n",
       "\n",
       "     -VentralDC  pericalcarine_volume  -Hippocampus   Putamen   Caudate  \\\n",
       "0      0.004498              0.002535      0.004372  0.005117  0.004709   \n",
       "1      0.003978              0.002612      0.003825  0.004903  0.003575   \n",
       "2      0.004404              0.001743      0.004377  0.005053  0.003914   \n",
       "3      0.003842              0.002555      0.003565  0.005305  0.003608   \n",
       "4      0.003802              0.003304      0.003456  0.004619  0.003857   \n",
       "..          ...                   ...           ...       ...       ...   \n",
       "136    0.004608              0.002107      0.004487  0.006393  0.004437   \n",
       "137    0.003766              0.002369      0.003947  0.004982  0.003704   \n",
       "138    0.004725              0.002690      0.004314  0.005037  0.004465   \n",
       "139    0.003965              0.002674      0.003505  0.004694  0.003493   \n",
       "140    0.004288              0.002861      0.003797  0.004984  0.003672   \n",
       "\n",
       "            S  gender_F  \n",
       "0    0.071429         1  \n",
       "1    0.468056         1  \n",
       "2    0.370714         1  \n",
       "3    0.047222         0  \n",
       "4    0.400928         1  \n",
       "..        ...       ...  \n",
       "136  0.190540         1  \n",
       "137  0.227739         0  \n",
       "138  0.314423         0  \n",
       "139  0.213333         0  \n",
       "140  0.117143         0  \n",
       "\n",
       "[141 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_excel('model_data_S_not_zero_absERROR_NotVent.xlsx').drop(columns = ['Unnamed: 0', 'abs_error_estimate'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 85) (141,)\n"
     ]
    }
   ],
   "source": [
    "# prep data into X and Y (X also scaled for the linear model)\n",
    "X = data.drop(columns = ['S'])\n",
    "X_scaled = MinMaxScaler().fit_transform(X) # REMARK -> transforming data here makes the model less generalizable\n",
    "Y = data.S\n",
    "print( X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new set of random values for the RANDOM feature for each new cv\n",
    "X_sc_df = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "X_sc_df.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X_sc_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOOCV LASSO REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.008)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.008)\n",
      "Lasso(alpha=0.008)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.003)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.010000000000000002)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.011)\n",
      "Lasso(alpha=0.012)\n",
      "Lasso(alpha=0.005)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.014000000000000002)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.013000000000000001)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.004)\n",
      "Lasso(alpha=0.012)\n",
      "MSE Lasso: 0.014 (0.016)\n",
      "MSE Baseline: 0.014 (0.015)\n"
     ]
    }
   ],
   "source": [
    "# initiate the storage for the data\n",
    "MSE_lasso = list()\n",
    "MSE_base = list()\n",
    "Y_preds = list()\n",
    "Y_trues = list()\n",
    "Y_means = list()\n",
    "coef = collections.defaultdict(list)\n",
    "alphas = list()\n",
    "\n",
    "# prep loocv\n",
    "cv = LeaveOneOut()\n",
    "cv.get_n_splits(X_sc_df)\n",
    "\n",
    "# make feature list\n",
    "feature_list = X_sc_df.keys().tolist()\n",
    "\n",
    "# execute the loocv\n",
    "for train_ix, test_ix in cv.split(X_sc_df):\n",
    "    \n",
    "    # create a new set of random values for the RANDOM feature for each new cv\n",
    "    X_sc_df.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X_sc_df)) \n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_sc_df.iloc[train_ix, :], X_sc_df.iloc[test_ix, :]\n",
    "    y_train, y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "\n",
    "    # create the model grid search for finetuning alpha (the inner loop)\n",
    "    cv_inner = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "    \n",
    "    # define model\n",
    "    model_s = linear_model.Lasso()\n",
    "    \n",
    "    # define grid\n",
    "    grid = {\"alpha\": np.arange(0.001, 0.999, 0.001)} \n",
    "\n",
    "    # fit the gridsearch\n",
    "    search = GridSearchCV(model_s, grid, scoring = 'neg_mean_squared_error', cv = cv_inner, n_jobs = 2)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # get best model from cross validated grid search \n",
    "    model = search.best_estimator_\n",
    "    alphas.append(model.alpha) # store alpha value resulting from the grid search\n",
    "    \n",
    "    # evaluate best Lasso model\n",
    "    y_pred = model.predict(X_test)\n",
    "    Y_preds.append(y_pred) # store predicted Y value\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    MSE_lasso.append(score) # store Lasso model score\n",
    "    \n",
    "    # store true Y value\n",
    "    Y_trues.append(y_test)\n",
    "    \n",
    "    # evaluate baseline\n",
    "    y_pred_base = [mean(y_train)]\n",
    "    Y_means.append(y_pred_base) # store base model Y value\n",
    "    score_base = mean_squared_error(y_test, y_pred_base)\n",
    "    MSE_base.append(score_base) # store base model score\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    # store coefficients of the features\n",
    "    coe = model.coef_\n",
    "    for feature, coeff in zip(feature_list, coe):\n",
    "        coef[feature].append(coeff)\n",
    "        \n",
    "# print mean MSE and its standarddeviation once finished the loocv\n",
    "print('MSE Lasso: %.3f (%.3f)' % (mean(MSE_lasso), std(MSE_lasso)))\n",
    "print('MSE Baseline: %.3f (%.3f)' % (mean(MSE_base), std(MSE_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for coefficients and save coefficients to excel\n",
    "coef_lasso = pd.DataFrame.from_dict(coef, orient = 'index')\n",
    "coef_lasso_tot = coef_lasso.copy()\n",
    "coef_lasso_tot['coefficient'] = coef_lasso.mean(axis = 1)\n",
    "coef_lasso_tot['std'] = coef_lasso.std(axis = 1)\n",
    "coef_lasso_tot.to_excel(\"coef_lasso_loocv.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of MSE of the lasso and Base model and save MSE to excel\n",
    "MSE = dict()\n",
    "MSE['lasso'] = MSE_lasso\n",
    "MSE['base'] = MSE_base\n",
    "MSE = pd.DataFrame.from_dict(MSE, orient = 'index')\n",
    "MSE_tot = MSE.copy()\n",
    "MSE_tot['mean'] = MSE.mean(axis = 1)\n",
    "MSE_tot['std'] = MSE.std(axis = 1)\n",
    "MSE_tot.to_excel(\"MSE_lasso_loocv.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y_pred, y_mean (base prediction), y_true and alpha and save to excel\n",
    "S_values = dict()\n",
    "S_values['y_pred'] = [item[0] for item in Y_preds]\n",
    "S_values['y_mean'] = [item[0] for item in Y_means]\n",
    "S_values['y_true'] = [float(item) for item in Y_trues]\n",
    "S_values['alpha'] = alphas\n",
    "S_value = pd.DataFrame.from_dict(S_values, orient = 'index')\n",
    "S_value.to_excel(\"S_values_lasso_loocv.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOOCV RANDOM FOREST REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted model: 0\n",
      "fitted model: 1\n",
      "fitted model: 2\n",
      "fitted model: 3\n",
      "fitted model: 4\n",
      "fitted model: 5\n",
      "fitted model: 6\n",
      "fitted model: 7\n",
      "fitted model: 8\n",
      "fitted model: 9\n",
      "fitted model: 10\n",
      "fitted model: 11\n",
      "fitted model: 12\n",
      "fitted model: 13\n",
      "fitted model: 14\n",
      "fitted model: 15\n",
      "fitted model: 16\n",
      "fitted model: 17\n",
      "fitted model: 18\n",
      "fitted model: 19\n",
      "fitted model: 20\n",
      "fitted model: 21\n",
      "fitted model: 22\n",
      "fitted model: 23\n",
      "fitted model: 24\n",
      "fitted model: 25\n",
      "fitted model: 26\n",
      "fitted model: 27\n",
      "fitted model: 28\n",
      "fitted model: 29\n",
      "fitted model: 30\n",
      "fitted model: 31\n",
      "fitted model: 32\n",
      "fitted model: 33\n",
      "fitted model: 34\n",
      "fitted model: 35\n",
      "fitted model: 36\n",
      "fitted model: 37\n",
      "fitted model: 38\n",
      "fitted model: 39\n",
      "fitted model: 40\n",
      "fitted model: 41\n",
      "fitted model: 42\n",
      "fitted model: 43\n",
      "fitted model: 44\n",
      "fitted model: 45\n",
      "fitted model: 46\n",
      "fitted model: 47\n",
      "fitted model: 48\n",
      "fitted model: 49\n",
      "fitted model: 50\n",
      "fitted model: 51\n",
      "fitted model: 52\n",
      "fitted model: 53\n",
      "fitted model: 54\n",
      "fitted model: 55\n",
      "fitted model: 56\n",
      "fitted model: 57\n",
      "fitted model: 58\n",
      "fitted model: 59\n",
      "fitted model: 60\n",
      "fitted model: 61\n",
      "fitted model: 62\n",
      "fitted model: 63\n",
      "fitted model: 64\n",
      "fitted model: 65\n",
      "fitted model: 66\n",
      "fitted model: 67\n",
      "fitted model: 68\n",
      "fitted model: 69\n",
      "fitted model: 70\n",
      "fitted model: 71\n",
      "fitted model: 72\n",
      "fitted model: 73\n",
      "fitted model: 74\n",
      "fitted model: 75\n",
      "fitted model: 76\n",
      "fitted model: 77\n",
      "fitted model: 78\n",
      "fitted model: 79\n",
      "fitted model: 80\n",
      "fitted model: 81\n",
      "fitted model: 82\n",
      "fitted model: 83\n",
      "fitted model: 84\n",
      "fitted model: 85\n",
      "fitted model: 86\n",
      "fitted model: 87\n",
      "fitted model: 88\n",
      "fitted model: 89\n",
      "fitted model: 90\n",
      "fitted model: 91\n",
      "fitted model: 92\n",
      "fitted model: 93\n",
      "fitted model: 94\n",
      "fitted model: 95\n",
      "fitted model: 96\n",
      "fitted model: 97\n",
      "fitted model: 98\n",
      "fitted model: 99\n",
      "fitted model: 100\n",
      "fitted model: 101\n",
      "fitted model: 102\n",
      "fitted model: 103\n",
      "fitted model: 104\n",
      "fitted model: 105\n",
      "fitted model: 106\n",
      "fitted model: 107\n",
      "fitted model: 108\n",
      "fitted model: 109\n",
      "fitted model: 110\n",
      "fitted model: 111\n",
      "fitted model: 112\n",
      "fitted model: 113\n",
      "fitted model: 114\n",
      "fitted model: 115\n",
      "fitted model: 116\n",
      "fitted model: 117\n",
      "fitted model: 118\n",
      "fitted model: 119\n",
      "fitted model: 120\n",
      "fitted model: 121\n",
      "fitted model: 122\n",
      "fitted model: 123\n",
      "fitted model: 124\n"
     ]
    }
   ],
   "source": [
    "# initiate storage of the data\n",
    "rf_feature_importance_perm = collections.defaultdict(list) # permutation of feature importances\n",
    "rf_feature_importance_perm_std = collections.defaultdict(list) # permutation of feature importances\n",
    "Y_preds_rf = list()\n",
    "Y_trues_rf = list()\n",
    "Y_means_rf = list()\n",
    "MSE_rf = list()\n",
    "MSE_base_rf = list()\n",
    "count = 0\n",
    "\n",
    "# prepare loocv\n",
    "cv_outer = LeaveOneOut()\n",
    "cv_outer.get_n_splits(X)\n",
    "\n",
    "# execute the loocv \n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    \n",
    "    # create a new set of random values for the RANDOM feature for each new cv\n",
    "    X.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X)) \n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "    y_train, y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "    # initiate and fit the model\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = 42, n_jobs = 2)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"fitted model:\", count)\n",
    "\n",
    "    # evaluate best RF model\n",
    "    y_pred = rf.predict(X_test)\n",
    "    Y_preds_rf.append(y_pred) # store predicted Y value\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    MSE_rf.append(score) # store RF model score\n",
    "    \n",
    "    # evaluate base model\n",
    "    y_base = [mean(y_train)]\n",
    "    Y_means_rf.append(y_base) # store base model Y value\n",
    "    score_base = mean_squared_error(y_test, y_base)\n",
    "    MSE_base_rf.append(score_base) # store base model score\n",
    "    \n",
    "    # store true Y value\n",
    "    Y_trues_rf.append(y_test) \n",
    "    \n",
    "    # initiate a list of all features\n",
    "    feature_list = X_train.keys().tolist()\n",
    "\n",
    "    # also store permutated feature importances and its standarddeviation\n",
    "    imp = permutation_importance(rf, X_train, y_train, scoring = 'neg_mean_squared_error', random_state = 0,  n_jobs = 2)\n",
    "    for item in imp:\n",
    "        if item == 'importances_mean':\n",
    "            for feature, importance in zip(feature_list, imp[item]):\n",
    "                rf_feature_importance_perm[feature].append(importance)       \n",
    "        if item == 'importances_std':\n",
    "            for feature, importance_std in zip(feature_list, imp[item]):\n",
    "                rf_feature_importance_perm_std[feature].append(importance_std)\n",
    "        \n",
    "    # increase count\n",
    "    count = count + 1\n",
    "\n",
    "# print mean MSE and its standarddeviation once finished the loocv\n",
    "print('MSE RF: %.3f (%.3f)' % (mean(MSE_rf), std(MSE_rf)))\n",
    "print('MSE Baseline: %.3f (%.3f)' % (mean(MSE_base), std(MSE_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of permutation importance and save to excel\n",
    "rf_fi_perm = pd.DataFrame.from_dict(rf_feature_importance_perm, orient = 'index')\n",
    "RF_perm = rf_fi_perm.copy()\n",
    "RF_perm['importance'] = rf_fi_perm.mean(axis = 1)\n",
    "RF_perm['std'] = rf_fi_perm.std(axis = 1)\n",
    "RF_perm.to_excel(\"RF_LOOCV_perm_importance.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of MSE of the rf and Base model and save MSE to excel\n",
    "MSE = dict()\n",
    "MSE['RF'] = MSE_rf\n",
    "MSE['base'] = MSE_base_rf\n",
    "MSE = pd.DataFrame.from_dict(MSE, orient = 'index')\n",
    "MSE_tot = MSE.copy()\n",
    "MSE_tot['mean'] = MSE.mean(axis = 1)\n",
    "MSE_tot['std'] = MSE.std(axis = 1)\n",
    "MSE_tot.to_excel(\"MSE_RF_LOOCV.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y_pred, y_mean (base prediction), y_true and alpha and save to excel\n",
    "S_values = dict()\n",
    "S_values['y_pred'] = [item[0] for item in Y_preds_rf]\n",
    "S_values['y_mean'] = [item[0] for item in Y_means_rf]\n",
    "S_values['y_true'] = [float(item) for item in Y_trues_rf]\n",
    "S_value = pd.DataFrame.from_dict(S_values, orient = 'index')\n",
    "S_value.to_excel(\"S_values_RF_loocv.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

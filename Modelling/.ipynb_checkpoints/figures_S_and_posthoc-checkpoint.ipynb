{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_excel('model_data_S_not_zero_absERROR_NotVent.xlsx').drop(columns = [\"Unnamed: 0\"])\n",
    "data_all_s = pd.read_excel('model_data_allS_absERROR_notVent.xlsx').drop(columns = [\"Unnamed: 0\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"N all S: \", len(data_all_s))\n",
    "\n",
    "print(\"max S: \", data_all_s.S.max())\n",
    "print(\"mean S: \", data_all_s.S.mean())\n",
    "print(\"std S: \", data_all_s.S.std())\n",
    "print(\"median S: \", data_all_s.S.median())\n",
    "print()\n",
    "print(\"N non zero S: \", len(data))\n",
    "print(\"max S: \", data.S.max())\n",
    "print(\"mean S: \", data.S.mean())\n",
    "print(\"std S: \", data.S.std())\n",
    "print(\"median S: \", data.S.median())\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(4)\n",
    "sns.set(font_scale = 1.5)\n",
    "sns.histplot(x = data_all_s.S, binwidth = 0.025, ax = ax[0]).set(xlim = (0, 0.6), ylim = (0,19), xlabel = 'Social information use (S)', title = 'A')\n",
    "sns.histplot(x = data.S, binwidth = 0.025, ax = ax[1]).set(xlim = (0, 0.6), ylim = (0, 19), xlabel = 'Social information use (S)', title = 'B')\n",
    "ax[1].set(ylabel=None)\n",
    "fig.savefig('histogram_all_S.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.S.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRELATIONS WITH S**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of correlations\n",
    "\n",
    "print(\"left postcentral + abs error: \", pearsonr(data['abs_error_estimate'], data['lh_postcentral_volume']))\n",
    "print(\"left postcentral + S: \", pearsonr(data['S'], data['lh_postcentral_volume']))\n",
    "print()\n",
    "\n",
    "print(\"right postcentral + abs error: \", pearsonr(data['abs_error_estimate'], data['rh_postcentral_volume']))\n",
    "print(\"right postcentral + S: \", pearsonr(data['S'], data['rh_postcentral_volume']))\n",
    "print()\n",
    "\n",
    "print(\"abs error + S: \", pearsonr(data['abs_error_estimate'], data['S']))\n",
    "print()\n",
    "\n",
    "print(\"pars triangularis + S: \", pearsonr(data['lh_parstriangularis_volume'], data['S']))\n",
    "print(\"pars triangularis + abs error: \", pearsonr(data['lh_parstriangularis_volume'], data['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left pallidum + S: \", pearsonr(data['Left-Pallidum'], data['S']))\n",
    "print(\"left pallidum + abs error: \", pearsonr(data['Left-Pallidum'], data['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"right entorhinal + S: \", pearsonr(data['rh_entorhinal_volume'], data['S']))\n",
    "print(\"right entorhinal + abs error: \", pearsonr(data['rh_entorhinal_volume'], data['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left entorhinal + S: \", pearsonr(data['lh_entorhinal_volume'], data['S']))\n",
    "print(\"left entorhinal + abs error: \", pearsonr(data['lh_entorhinal_volume'], data['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left caudal middle frontal + S: \", pearsonr(data['lh_caudalmiddlefrontal_volume'], data['S']))\n",
    "print(\"left caudal middle frontal + abs error: \", pearsonr(data['lh_caudalmiddlefrontal_volume'], data['abs_error_estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "x = data['lh_parstriangularis_volume']\n",
    "y = data['S']\n",
    "sns.regplot(ax = axs[0,0], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[0,0].set_ylabel('Social information use (S)', fontsize = 13)\n",
    "axs[0,0].set_xlabel('left pars triangularis GM volume', fontsize = 13)\n",
    "axs[0,0].set_title('A', fontsize = 15, loc = 'left')\n",
    "axs[0,0].text(0.0050 - 0.00015, 0.53, \"r = 0.261\", ha=\"left\", va=\"top\", fontsize = 15)\n",
    "axs[0,0].set(xlim = (0.0024, 0.0056))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[0,0].get_xticks()]\n",
    "axs[0,0].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "x = data['lh_postcentral_volume']\n",
    "y = data['S']\n",
    "sns.regplot(ax = axs[1,0], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[1,0].set_ylabel('Social information use (S)', fontsize = 13)\n",
    "axs[1,0].set_xlabel('left postcentral GM volume', fontsize = 13)\n",
    "axs[1,0].set_title('C', fontsize = 15, loc = 'left')\n",
    "axs[1,0].text(0.012 - 0.0002, 0.53, \"r = -0.177\", ha=\"left\", va=\"top\", fontsize = 15)\n",
    "axs[1,0].set(xlim = (0.0079, 0.0131))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[1,0].get_xticks()]\n",
    "axs[1,0].set_xticklabels(xlabels)\n",
    "\n",
    "x = data['lh_caudalmiddlefrontal_volume']\n",
    "y = data['S']\n",
    "sns.regplot(ax = axs[0,1], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[0,1].set_ylabel('Social information use (S)', fontsize = 13)\n",
    "axs[0,1].set_xlabel('left caudalmiddlefrontal GM volume', fontsize = 13)\n",
    "axs[0,1].set_title('B', fontsize = 15, loc = 'left')\n",
    "axs[0,1].text(0.0084, 0.53, \"r = -0.190\", ha=\"left\", va=\"top\", fontsize = 15)\n",
    "axs[0,1].set(xlim = (0.0047, 0.0095))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[0,1].get_xticks()]\n",
    "axs[0,1].set_xticklabels(xlabels)\n",
    "\n",
    "x = data['rh_entorhinal_volume']\n",
    "y = data['S']\n",
    "sns.regplot(ax = axs[1,1], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[1,1].set_ylabel('Social information use (S)', fontsize = 13)\n",
    "axs[1,1].set_xlabel('right entorhinal GM volume', fontsize = 13)\n",
    "axs[1,1].set_title('D', fontsize = 15, loc = 'left')\n",
    "axs[1,1].text(0.00245, 0.53, \"r = 0.177\", ha=\"left\", va=\"top\", fontsize = 15)\n",
    "axs[1,1].set(xlim = (0.0009, 0.0029))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[1,1].get_xticks()]\n",
    "axs[1,1].set_xticklabels(xlabels)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "sns.set(font_scale = 0.91)\n",
    "plt.savefig('S_correlation_plots.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRELATIONS WITH ABS ERROR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_figwidth(12)\n",
    "# fig.set_figheight(12)\n",
    "\n",
    "x = data['rh_postcentral_volume']\n",
    "y = data['abs_error_estimate']\n",
    "sns.regplot(ax = axs[0], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[0].set_ylabel('Absolute error first estimate', fontsize = 13)\n",
    "axs[0].set_xlabel('right postcentral GM volume', fontsize = 13)\n",
    "axs[0].set_title('A', fontsize = 15, loc = 'left')\n",
    "axs[0].text(0.01085, 42, \"r = -0.237\", ha=\"left\", va=\"top\",  fontsize = 15)\n",
    "axs[0].set(xlim = (0.00755, 0.0119))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[0].get_xticks()]\n",
    "axs[0].set_xticklabels(xlabels)\n",
    "\n",
    "x = data['lh_caudalmiddlefrontal_volume']\n",
    "y = data['abs_error_estimate']\n",
    "sns.regplot(ax = axs[1], x= x, y = y, color = 'green', ci = 95, scatter_kws={'s':20}).set(xlabel=None, ylabel=None)\n",
    "axs[1].set_ylabel('Absolute error first estimate', fontsize = 13)\n",
    "axs[1].set_xlabel('left caudalmiddlefrontal GM volume', fontsize = 13)\n",
    "axs[1].set_title('B', fontsize = 15, loc = 'left')\n",
    "axs[1].text(0.0084, 42, \"r = -0.223\", ha=\"left\", va=\"top\", fontsize = 15)\n",
    "axs[1].set(xlim = (0.0046, 0.0096))\n",
    "xlabels = ['{:,.4f}'.format(x) for x in axs[1].get_xticks()]\n",
    "axs[1].set_xticklabels(xlabels)\n",
    "\n",
    "sns.set(font_scale = 0.91)\n",
    "\n",
    "plt.savefig('error_postcentral_caudal.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ALL S**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of correlations\n",
    "\n",
    "print(\"left postcentral + abs error: \", pearsonr(data_all_s['abs_error_estimate'], data_all_s['lh_postcentral_volume']))\n",
    "print(\"left postcentral + S: \", pearsonr(data_all_s['S'], data_all_s['lh_postcentral_volume']))\n",
    "print()\n",
    "\n",
    "print(\"right postcentral + abs error: \", pearsonr(data_all_s['abs_error_estimate'], data_all_s['rh_postcentral_volume']))\n",
    "print(\"right postcentral + S: \", pearsonr(data_all_s['S'], data_all_s['rh_postcentral_volume']))\n",
    "print()\n",
    "\n",
    "print(\"abs error + S: \", pearsonr(data_all_s['abs_error_estimate'], data_all_s['S']))\n",
    "print()\n",
    "\n",
    "print(\"pars triangularis + S: \", pearsonr(data_all_s['lh_parstriangularis_volume'], data_all_s['S']))\n",
    "print(\"pars triangularis + abs error: \", pearsonr(data_all_s['lh_parstriangularis_volume'], data_all_s['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left pallidum + S: \", pearsonr(data_all_s['Left-Pallidum'], data_all_s['S']))\n",
    "print(\"left pallidum + abs error: \", pearsonr(data_all_s['Left-Pallidum'], data_all_s['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"right entorhinal + S: \", pearsonr(data_all_s['rh_entorhinal_volume'], data_all_s['S']))\n",
    "print(\"right entorhinal + abs error: \", pearsonr(data_all_s['rh_entorhinal_volume'], data_all_s['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left entorhinal + S: \", pearsonr(data_all_s['lh_entorhinal_volume'], data_all_s['S']))\n",
    "print(\"left entorhinal + abs error: \", pearsonr(data_all_s['lh_entorhinal_volume'], data_all_s['abs_error_estimate']))\n",
    "print()\n",
    "\n",
    "print(\"left caudal middle frontal + S: \", pearsonr(data_all_s['lh_caudalmiddlefrontal_volume'], data_all_s['S']))\n",
    "print(\"left caudal middle frontal + abs error: \", pearsonr(data_all_s['lh_caudalmiddlefrontal_volume'], data_all_s['abs_error_estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlations with data including participants with no social information use\n",
    "features_interest = ['lh_parstriangularis_volume', 'rh_parstriangularis_volume', \n",
    "                     'lh_postcentral_volume', 'rh_postcentral_volume', \n",
    "                     'lh_caudalmiddlefrontal_volume', 'rh_caudalmiddlefrontal_volume', \n",
    "                     'Left-Pallidum', 'Right-Pallidum',\n",
    "                     'lh_entorhinal_volume', 'rh_entorhinal_volume',\n",
    "                    'Right-Thalamus-Proper', 'Left-Thalamus-Proper']\n",
    "\n",
    "corr_dict = dict()\n",
    "\n",
    "for item in features_interest:\n",
    "    feature_dict = dict()\n",
    "    \n",
    "    for x in ['S', 'abs_error_estimate']:\n",
    "        \n",
    "        corr_1 = pearsonr(data[item], data[x])\n",
    "        if corr_1[1] < 0.05:\n",
    "            r_1 = round(corr_1[0], 4)\n",
    "            p_1 = round(corr_1[1], 4)\n",
    "        else:\n",
    "            r_1 = 0\n",
    "            p_1 = 0\n",
    "        \n",
    "        feature_dict[x] = r_1\n",
    "        feature_dict[x + '_p'] = p_1\n",
    "        \n",
    "        corr_2 = pearsonr(data_all_s[item], data_all_s[x])\n",
    "        if corr_2[1] < 0.05:\n",
    "            r_2 = round(corr_2[0], 4)\n",
    "            p_2 = round(corr_2[1], 4)\n",
    "        else:\n",
    "            r_2 = 0\n",
    "            p_2 = 0\n",
    "            \n",
    "        feature_dict[x + \"_allS\"] = r_2\n",
    "        feature_dict[x + '_allS_p'] = p_2\n",
    "    corr_dict[item] = feature_dict\n",
    "\n",
    "overview_corr = pd.DataFrame.from_dict(corr_dict).transpose()[['S', 'S_p', 'abs_error_estimate', 'abs_error_estimate_p', \n",
    "                                                               'S_allS', 'S_allS_p', 'abs_error_estimate_allS', 'abs_error_estimate_allS_p']]\n",
    "overview_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel\n",
    "overview_corr.to_excel(\"correlations_overview.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

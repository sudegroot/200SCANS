{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from rfpimp import * # might not be installed already, otherwise install using pip install\n",
    "import collections\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_excel('model_data_S_not_zero_absERROR_NotVent.xlsx').drop(columns = ['Unnamed: 0', 'abs_error_estimate'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data into X and Y (X also scaled for the linear model)\n",
    "X = data.drop(columns = ['S'])\n",
    "X_RF = X[['lh_parstriangularis_volume', 'lh_postcentral_volume', 'Left-Pallidum',\n",
    "       'rh_postcentral_volume', 'rh_paracentral_volume',\n",
    "       'lh_superiortemporal_volume', 'lh_parsorbitalis_volume', 'Putamen',\n",
    "       'lh_caudalmiddlefrontal_volume', 'Right-Amygdala',\n",
    "       'lh_entorhinal_volume', 'lh_fusiform_volume', 'Right-Pallidum',\n",
    "       '-VentralDC', 'rh_supramarginal_volume', 'rh_parsopercularis_volume',\n",
    "       'Left-Accumbens-area', 'CC_Posterior', 'lh_lateralorbitofrontal_volume',\n",
    "       'rh_lateralorbitofrontal_volume', 'lh_inferiortemporal_volume']]\n",
    "X_lasso = X[['lh_caudalmiddlefrontal_volume', 'lh_entorhinal_volume',\n",
    "       'lh_fusiform_volume', 'lh_parsorbitalis_volume',\n",
    "       'lh_parstriangularis_volume', 'lh_postcentral_volume',\n",
    "       'lh_superiorparietal_volume', 'lh_superiortemporal_volume',\n",
    "       'rh_entorhinal_volume', 'rh_postcentral_volume',\n",
    "       'rh_rostralanteriorcingulate_volume', 'rh_transversetemporal_volume',\n",
    "       'Left-Accumbens-area', 'gender_F']]\n",
    "X_scaled = MinMaxScaler().fit_transform(X_lasso) \n",
    "Y = data.S\n",
    "print( X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new set of random values for the RANDOM feature for each new cv\n",
    "X_sc_df = pd.DataFrame(X_scaled, columns = X_lasso.columns)\n",
    "X_sc_df.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X_sc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOOCV LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the storage for the data\n",
    "MSE_lasso = list()\n",
    "MSE_base = list()\n",
    "Y_preds = list()\n",
    "Y_trues = list()\n",
    "Y_means = list()\n",
    "coef = collections.defaultdict(list)\n",
    "alphas = list()\n",
    "\n",
    "# prep loocv\n",
    "cv = LeaveOneOut()\n",
    "cv.get_n_splits(X_sc_df)\n",
    "\n",
    "# make feature list\n",
    "feature_list = X_sc_df.keys().tolist()\n",
    "\n",
    "# execute the loocv\n",
    "for train_ix, test_ix in cv.split(X_sc_df):\n",
    "    \n",
    "    # create a new set of random values for the RANDOM feature for each new cv\n",
    "    X_sc_df.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X_sc_df)) \n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_sc_df.iloc[train_ix, :], X_sc_df.iloc[test_ix, :]\n",
    "    y_train, y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "\n",
    "    # create the model grid search for finetuning alpha (the inner loop)\n",
    "    cv_inner = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "    \n",
    "    # define model\n",
    "    model_s = linear_model.Lasso()\n",
    "    \n",
    "    # define grid\n",
    "    grid = {\"alpha\": np.arange(0.001, 0.999, 0.001)} \n",
    "\n",
    "    # fit the gridsearch\n",
    "    search = GridSearchCV(model_s, grid, scoring = 'neg_mean_squared_error', cv = cv_inner, n_jobs = 2)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # get best model from cross validated grid search \n",
    "    model = search.best_estimator_\n",
    "    alphas.append(model.alpha) # store alpha value resulting from the grid search\n",
    "    \n",
    "    # evaluate best Lasso model\n",
    "    y_pred = model.predict(X_test)\n",
    "    Y_preds.append(y_pred) # store predicted Y value\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    MSE_lasso.append(score) # store Lasso model score\n",
    "    \n",
    "    # store true Y value\n",
    "    Y_trues.append(y_test)\n",
    "    \n",
    "    # evaluate baseline\n",
    "    y_pred_base = [mean(y_train)]\n",
    "    Y_means.append(y_pred_base) # store base model Y value\n",
    "    score_base = mean_squared_error(y_test, y_pred_base)\n",
    "    MSE_base.append(score_base) # store base model score\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    # store coefficients of the features\n",
    "    coe = model.coef_\n",
    "    for feature, coeff in zip(feature_list, coe):\n",
    "        coef[feature].append(coeff)\n",
    "        \n",
    "# print mean MSE and its standarddeviation once finished the loocv\n",
    "print('MSE Lasso: %.3f (%.3f)' % (mean(MSE_lasso), std(MSE_lasso)))\n",
    "print(stats.sem(MSE_lasso))\n",
    "print('MSE Baseline: %.3f (%.3f)' % (mean(MSE_base), std(MSE_base)))\n",
    "print(stats.sem(MSE_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mean MSE and its standarddeviation once finished the loocv\n",
    "print('MSE Lasso: %.4f (%.4f)' % (mean(MSE_lasso), std(MSE_lasso)))\n",
    "print(stats.sem(MSE_lasso))\n",
    "print('MSE Baseline: %.3f (%.3f)' % (mean(MSE_base), std(MSE_base)))\n",
    "print(stats.sem(MSE_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for coefficients and save coefficients to excel\n",
    "coef_lasso = pd.DataFrame.from_dict(coef, orient = 'index')\n",
    "coef_lasso_tot = coef_lasso.copy()\n",
    "coef_lasso_tot['coefficient'] = coef_lasso.mean(axis = 1)\n",
    "coef_lasso_tot['std'] = coef_lasso.std(axis = 1)\n",
    "coef_lasso_tot.to_excel(\"coef_lasso_loocv_nonzero_bestmodel.xlsx\")\n",
    "coef_lasso_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_lasso_tot = pd.read_excel(\"coef_lasso_loocv_nonzero.xlsx\").set_index('Unnamed: 0')\n",
    "# coef_lasso_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_lasso_tot['abs'] = np.abs(coef_lasso_tot.coefficient) #coef_lasso_tot.apply(lambda row: row.coefficient, axis = 1)\n",
    "coef_lasso_tot = coef_lasso_tot.sort_values(by = ['abs'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_lasso_tot\n",
    "\n",
    "features_list = [item for item in coef_lasso_tot.index]\n",
    "features_list\n",
    "\n",
    "\n",
    "vis_coef = dict()\n",
    "\n",
    "for item in features_list:\n",
    "    vis_coef[item] = coef_lasso_tot.drop(columns = ['coefficient', 'std']).loc[item]\n",
    "\n",
    "vis_coef = pd.DataFrame.from_dict(vis_coef)\n",
    "vis_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of MSE of the lasso and Base model and save MSE to excel\n",
    "MSE = dict()\n",
    "MSE['lasso'] = MSE_lasso\n",
    "MSE['base'] = MSE_base\n",
    "MSE = pd.DataFrame.from_dict(MSE, orient = 'index')\n",
    "MSE_tot = MSE.copy()\n",
    "MSE_tot['mean'] = MSE.mean(axis = 1)\n",
    "MSE_tot['std'] = MSE.std(axis = 1)\n",
    "MSE_tot.to_excel(\"MSE_lasso_loocv_bestmodel_nonzero.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y_pred, y_mean (base prediction), y_true and alpha and save to excel\n",
    "S_values = dict()\n",
    "S_values['y_pred'] = [item[0] for item in Y_preds]\n",
    "S_values['y_mean'] = [item[0] for item in Y_means]\n",
    "S_values['y_true'] = [float(item) for item in Y_trues]\n",
    "S_values['alpha'] = alphas\n",
    "S_value = pd.DataFrame.from_dict(S_values, orient = 'index')\n",
    "S_value.to_excel(\"S_values_lasso_loocv_bestmodel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOOCV RANDOM FOREST REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate storage of the data\n",
    "rf_feature_importance_perm = collections.defaultdict(list) # permutation of feature importances\n",
    "rf_feature_importance_perm_std = collections.defaultdict(list) # permutation of feature importances\n",
    "Y_preds_rf = list()\n",
    "Y_trues_rf = list()\n",
    "Y_means_rf = list()\n",
    "MSE_rf = list()\n",
    "MSE_base_rf = list()\n",
    "count = 0\n",
    "\n",
    "# prepare loocv\n",
    "cv_outer = LeaveOneOut()\n",
    "cv_outer.get_n_splits(X_RF)\n",
    "\n",
    "# execute the loocv \n",
    "for train_ix, test_ix in cv_outer.split(X_RF):\n",
    "    \n",
    "    # create a new set of random values for the RANDOM feature for each new cv\n",
    "    X_RF.loc[:, ('RANDOM')] = np.random.uniform(0,1, size = len(X_RF)) \n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test = X_RF.iloc[train_ix, :], X_RF.iloc[test_ix, :]\n",
    "    y_train, y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n",
    "    \n",
    "    # initiate and fit the model\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = 42, n_jobs = 2)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"fitted model:\", count)\n",
    "\n",
    "    # evaluate best RF model\n",
    "    y_pred = rf.predict(X_test)\n",
    "    Y_preds_rf.append(y_pred) # store predicted Y value\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    MSE_rf.append(score) # store RF model score\n",
    "    \n",
    "    # evaluate base model\n",
    "    y_base = [mean(y_train)]\n",
    "    Y_means_rf.append(y_base) # store base model Y value\n",
    "    score_base = mean_squared_error(y_test, y_base)\n",
    "    MSE_base_rf.append(score_base) # store base model score\n",
    "    \n",
    "    # store true Y value\n",
    "    Y_trues_rf.append(y_test) \n",
    "    \n",
    "    # initiate a list of all features\n",
    "    feature_list = X_train.keys().tolist()\n",
    "\n",
    "    # also store permutated feature importances and its standarddeviation\n",
    "    imp = permutation_importance(rf, X_train, y_train, scoring = 'neg_mean_squared_error', random_state = 0,  n_jobs = 2)\n",
    "    for item in imp:\n",
    "        if item == 'importances_mean':\n",
    "            for feature, importance in zip(feature_list, imp[item]):\n",
    "                rf_feature_importance_perm[feature].append(importance)       \n",
    "        if item == 'importances_std':\n",
    "            for feature, importance_std in zip(feature_list, imp[item]):\n",
    "                rf_feature_importance_perm_std[feature].append(importance_std)\n",
    "        \n",
    "    # increase count\n",
    "    count = count + 1\n",
    "\n",
    "# print mean MSE and its standarddeviation once finished the loocv\n",
    "print('MSE RF: %.4f (%.4f)' % (mean(MSE_rf), std(MSE_rf)))\n",
    "print(stats.sem(MSE_rf))\n",
    "print('MSE Baseline: %.4f (%.4f)' % (mean(MSE_base_rf), std(MSE_base_rf)))\n",
    "print(stats.sem(MSE_base_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of permutation importance and save to excel\n",
    "rf_fi_perm = pd.DataFrame.from_dict(rf_feature_importance_perm, orient = 'index')\n",
    "RF_perm = rf_fi_perm.copy()\n",
    "RF_perm['importance'] = rf_fi_perm.mean(axis = 1)\n",
    "RF_perm['std'] = rf_fi_perm.std(axis = 1)\n",
    "RF_perm.to_excel(\"RF_LOOCV_perm_importance_bestmodel_nonzero.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std of MSE of the lasso and Base model and save MSE to excel\n",
    "MSE = dict()\n",
    "MSE['RF'] = MSE_rf\n",
    "MSE['base'] = MSE_base_rf\n",
    "MSE = pd.DataFrame.from_dict(MSE, orient = 'index')\n",
    "MSE_tot = MSE.copy()\n",
    "MSE_tot['mean'] = MSE.mean(axis = 1)\n",
    "MSE_tot['std'] = MSE.std(axis = 1)\n",
    "MSE_tot.to_excel(\"MSE_RF_LOOCV_bestmodel_nonzero.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y_pred, y_mean (base prediction), y_true and alpha and save to excel\n",
    "S_values = dict()\n",
    "S_values['y_pred'] = [item[0] for item in Y_preds_rf]\n",
    "S_values['y_mean'] = [item[0] for item in Y_means_rf]\n",
    "S_values['y_true'] = [float(item) for item in Y_trues_rf]\n",
    "S_value = pd.DataFrame.from_dict(S_values, orient = 'index')\n",
    "S_value.to_excel(\"S_values_RF_loocv_bestmodel.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
